# -*- coding: utf-8 -*-
"""Копия блокнота "Обнаружение заголовков.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sKSd0xKlbUHQl6RhBzqj4byT-MjxR7DR

Модель для обработки excel
"""

import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score
from sklearn.feature_extraction.text import TfidfVectorizer

# Чтение данных из одного Excel файла
def load_excel_data(file_path: str) -> pd.DataFrame:
    df = pd.read_excel(file_path)

    # Добавляем столбец 'is_header', помечаем первую строку как заголовок
    df['is_header'] = 0  # По умолчанию все строки - не заголовки
    if not df.empty:
        df.loc[0, 'is_header'] = 1  # Первая строка - заголовок

    return df

# Предобработка данных
def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    df = df.dropna(how='all')  # Удаляем полностью пустые строки
    df['text'] = df.apply(lambda row: ' '.join(row.drop('is_header').astype(str)), axis=1)  # Объединяем все столбцы в строку
    return df[['text', 'is_header']]  # Оставляем только текст и метку заголовка

# Обучение моделей
def train_models(X, y):
    # Разделяем данные на обучающие и тестовые
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # Обучение Random Forest
    rf_model = RandomForestClassifier(random_state=42)
    rf_model.fit(X_train, y_train)
    y_pred_rf = rf_model.predict(X_test)
    print("Random Forest Classification Report:")
    print(classification_report(y_test, y_pred_rf))
    print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.2f}")

    # Обучение SVM
    svm_model = SVC(kernel='linear', random_state=42)
    svm_model.fit(X_train, y_train)
    y_pred_svm = svm_model.predict(X_test)
    print("SVM Classification Report:")
    print(classification_report(y_test, y_pred_svm))
    print(f"Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}")

# Функция для объединения всех Excel файлов в одном DataFrame
def load_all_excel_from_directory(directory: str) -> pd.DataFrame:
    all_data = pd.DataFrame()  # Пустой DataFrame для всех данных
    for filename in os.listdir(directory):
        if filename.endswith(".xlsx") or filename.endswith(".xls"):  # Проверяем только Excel файлы
            file_path = os.path.join(directory, filename)
            df = load_excel_data(file_path)  # Загружаем данные из Excel файла
            all_data = pd.concat([all_data, df], ignore_index=True)  # Объединяем все данные
    return all_data

# Основной процесс
def main_excel_solution(directory: str):
    df = load_all_excel_from_directory(directory)  # Загрузка всех Excel файлов из директории
    if df.empty:
        print("Нет доступных данных для обработки")
        return

    df = preprocess_data(df)  # Предобработка данных

    # Определение признаков (X) и целевой переменной (y)
    X = df['text']  # Признаки - текст
    y = df['is_header']  # Целевая переменная - метка заголовка

    # Преобразование текстовых данных в числовые вектора с использованием TfidfVectorizer
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(X)  # Преобразуем текст в числовые вектора

    # Обучение моделей
    train_models(X, y)

# Пример использования
excel_directory_path = '/content/data'  # Путь к папке с Excel файлами
main_excel_solution(excel_directory_path)

"""Модель для обработки CSV"""

import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score
from sklearn.feature_extraction.text import TfidfVectorizer

# Чтение данных из одного CSV файла с указанием разделителя и обработкой ошибок
def load_csv_data(file_path: str) -> pd.DataFrame:
    try:
        # Читаем файл CSV, обрабатывая строки с ошибками и поддерживая разные форматы
        df = pd.read_csv(file_path, delimiter=',', on_bad_lines='skip')

        # Добавляем столбец 'is_header', помечаем первую строку как заголовок
        df['is_header'] = 0  # По умолчанию все строки - не заголовки
        if not df.empty:
            df.loc[0, 'is_header'] = 1  # Первая строка - заголовок
        return df
    except Exception as e:
        print(f"Ошибка при чтении файла {file_path}: {e}")
        return pd.DataFrame()  # Возвращаем пустой DataFrame в случае ошибки

# Предобработка данных
def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    df = df.dropna(how='all')  # Удаляем полностью пустые строки
    # Преобразуем все столбцы в строки, чтобы избежать проблем с типами данных
    df = df.astype(str)

    # Объединяем все столбцы в одну строку текста
    df['text'] = df.apply(lambda row: ' '.join(row.drop('is_header').astype(str)), axis=1)

    return df[['text', 'is_header']]  # Оставляем только текст и метку заголовка

# Обучение моделей
def train_models(X, y):
    # Разделяем данные на обучающие и тестовые
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # Обучение Random Forest
    rf_model = RandomForestClassifier(random_state=42)
    rf_model.fit(X_train, y_train)
    y_pred_rf = rf_model.predict(X_test)
    print("Random Forest Classification Report:")
    print(classification_report(y_test, y_pred_rf))
    print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.2f}")

    # Обучение SVM
    svm_model = SVC(kernel='linear', random_state=42)
    svm_model.fit(X_train, y_train)
    y_pred_svm = svm_model.predict(X_test)
    print("SVM Classification Report:")
    print(classification_report(y_test, y_pred_svm))
    print(f"Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}")

# Функция для объединения всех CSV файлов в одном DataFrame
def load_all_csv_from_directory(directory: str) -> pd.DataFrame:
    all_data = pd.DataFrame()  # Пустой DataFrame для всех данных
    for filename in os.listdir(directory):
        if filename.endswith(".csv"):
            file_path = os.path.join(directory, filename)
            df = load_csv_data(file_path)  # Загружаем данные из CSV файла
            if not df.empty:
                all_data = pd.concat([all_data, df], ignore_index=True)  # Объединяем все данные
    return all_data

# Основной процесс
def main_csv_solution(directory: str):
    df = load_all_csv_from_directory(directory)  # Загрузка всех CSV файлов из директории
    if df.empty:
        print("Нет доступных данных для обработки")
        return

    df = preprocess_data(df)  # Предобработка данных

    # Определение признаков (X) и целевой переменной (y)
    X = df['text']  # Признаки - текст
    y = df['is_header']  # Целевая переменная - метка заголовка

    # Преобразование текстовых данных в числовые вектора с использованием TfidfVectorizer
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(X)  # Преобразуем текст в числовые вектора

    # Обучение моделей
    train_models(X, y)

# Пример использования
csv_directory_path = '/content/data'  # Путь к папке с CSV файлами
main_csv_solution(csv_directory_path)